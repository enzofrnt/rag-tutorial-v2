import argparse
import os
import shutil

from django.conf import settings
from langchain.schema.document import Document
from langchain_chroma import Chroma
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter

from .get_embedding_function import get_embedding_function


def populate_database():
    """
    Charge les documents, les segmente en morceaux et les ajoute √† la base de donn√©es Chroma.
    """
    documents = load_documents()
    chunks = split_documents(documents)
    # add_to_chroma(chunks)
    add_to_django(chunks)


def reset_database():
    """
    R√©initialise compl√®tement la base de donn√©es en supprimant tout son contenu.
    """
    clear_database()


def load_documents():
    """
    Charge les documents PDF depuis un r√©pertoire sp√©cifi√© dans les param√®tres Django.

    :return: Liste de documents charg√©s.
    """
    document_loader = PyPDFDirectoryLoader(settings.DATA_PATH)
    return document_loader.load()


def split_documents(documents: list[Document]):
    """
    Divise les documents en morceaux de taille contr√¥l√©e pour l'indexation.

    :param documents: Liste de documents √† segmenter.
    :return: Liste de morceaux de texte segment√©s.
    """
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=800,  # Taille maximale d'un morceau (en caract√®res).
        chunk_overlap=80,  # Chevauchement entre les morceaux pour la continuit√©.
        length_function=len,  # Fonction pour mesurer la longueur des morceaux.
        is_separator_regex=False,  # Indique que le s√©parateur n'est pas une expression r√©guli√®re.
    )
    return text_splitter.split_documents(documents)


def add_to_chroma(chunks: list[Document]):
    """
    Ajoute des morceaux de texte √† la base de donn√©es Chroma.
    √âvite d'ajouter des documents d√©j√† pr√©sents dans la base.

    :param chunks: Liste de morceaux de texte √† ajouter.
    """
    # Charger la base de donn√©es existante
    db = Chroma(
        persist_directory=settings.CHROMA_PATH,
        embedding_function=get_embedding_function(),
    )

    # Calculer les identifiants uniques pour chaque morceau
    chunks_with_ids = calculate_chunk_ids(chunks)

    # V√©rifier les documents existants dans la base
    existing_items = db.get(include=[])
    existing_ids = set(existing_items["ids"])
    print(f"Nombre de documents existants dans la base : {len(existing_ids)}")

    # Ajouter uniquement les nouveaux documents
    new_chunks = [
        chunk for chunk in chunks_with_ids if chunk.metadata["id"] not in existing_ids
    ]

    if new_chunks:
        print(f"üëâ Ajout de nouveaux documents : {len(new_chunks)}")
        new_chunk_ids = [chunk.metadata["id"] for chunk in new_chunks]
        db.add_documents(new_chunks, ids=new_chunk_ids)
    else:
        print("‚úÖ Aucun nouveau document √† ajouter")


from django.db.utils import IntegrityError

from .models import Chunk


def add_to_django(chunks: list[Document]):
    """
    Ajoute les morceaux de texte √† la base de donn√©es Django.
    Ignore les documents d√©j√† pr√©sents.

    :param chunks: Liste de morceaux de texte √† ajouter.
    """
    embedding_function = get_embedding_function()

    for chunk in chunks:
        # Calculer l'embedding pour le contenu
        embedding = embedding_function.embed_query(chunk.page_content)

        # Extraire les m√©tadonn√©es
        source = chunk.metadata.get("source")
        page = int(chunk.metadata.get("page", 0))
        chunk_index = int(chunk.metadata.get("id", "0").split(":")[-1])

        # Cr√©er et sauvegarder l'objet dans la base
        try:
            Chunk.objects.create(
                source=source,
                page=page,
                chunk_index=chunk_index,
                content=chunk.page_content,
                embedding=embedding,
            )
            print(f"‚úÖ Chunk ajout√© : {source} - Page {page}, Chunk {chunk_index}")
        except IntegrityError:
            print(
                f"‚õî Chunk d√©j√† existant : {source} - Page {page}, Chunk {chunk_index}"
            )


def calculate_chunk_ids(chunks):
    """
    Calcule des identifiants uniques pour chaque morceau bas√© sur la source, la page et l'index.

    :param chunks: Liste de morceaux de texte.
    :return: Liste de morceaux avec des identifiants ajout√©s.
    """
    last_page_id = None
    current_chunk_index = 0

    for chunk in chunks:
        source = chunk.metadata.get(
            "source"
        )  # Source du document (par exemple, le nom du fichier PDF).
        page = chunk.metadata.get("page")  # Num√©ro de la page.
        current_page_id = f"{source}:{page}"  # ID unique pour la page (source:page).

        # Incr√©mente l'index si le morceau appartient √† la m√™me page que le pr√©c√©dent.
        if current_page_id == last_page_id:
            current_chunk_index += 1
        else:
            current_chunk_index = 0

        # G√©n√®re un ID unique pour le morceau.
        chunk_id = f"{current_page_id}:{current_chunk_index}"
        last_page_id = current_page_id

        # Ajoute l'ID au metadata du morceau.
        chunk.metadata["id"] = chunk_id

    return chunks


def clear_database():
    """
    Supprime compl√®tement le contenu de la base de donn√©es Chroma en effa√ßant le dossier correspondant.

    :return: None
    """
    if os.path.exists(settings.CHROMA_PATH):
        shutil.rmtree(settings.CHROMA_PATH)
